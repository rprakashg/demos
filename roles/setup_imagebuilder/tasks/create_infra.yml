---
- name: generate tf scripts
  block:
  - name: create temp directory to store terraform scripts
    ansible.builtin.tempfile:
      state: directory
      suffix: terraform
    register: tfdir
  
  - name: debug tfdir path
    ansible.builtin.debug:
      var: tfdir.path

  - name: create tf script
    ansible.builtin.copy:
      dest: "{{ tfdir.path }}/main.tf"
      content: | 
        provider "aws" {
          region = var.region
        }
        
        data "aws_availability_zones" "available" {}
        data "aws_caller_identity" "current" {}

        resource "aws_key_pair" "sshkeypair" {
          key_name   = var.ssh_key
          public_key = file("~/.ssh/${var.ssh_key}.pub")
        }

        locals {
            azs                     = slice(data.aws_availability_zones.available.names, 0, 2)
            vpc_cidr                = "10.0.0.0/16" 
            account_id              = data.aws_caller_identity.current.account_id

            tags = {
                stack: var.stack
            }
        }

        # variables
        variable "region" {
          description = "AWS region"
          type        = string
        }

        variable "stack" {
          description = "Name of Stack"
          type        = string
        }

        variable instance_name {
          description = "EC2 instance name"
          type        = string
        }

        variable "instance_type" {
          description = "EC2 instance type to use"  
          type = string
        }

        variable ssh_key {
          description = "SSH key pair name"
          type        = string
        }

        variable "ami" {
          description = "AMI to use"
          type = string
        }

        variable "admin_user" {
          description = "Default password for ec2-user account"
          type = string
        }

        variable "admin_password" {
          description = "Default password for ec2-user account"
          type = string
        }

        variable "my_ip" {
          description = "ISP public IP"
          type = string
        }

        variable "iso_bucket_name" {
          description = "S3 Storage bucket for storing downloadable ISO installers"
          type        = string
        }

        variable "ami_bucket_name" {
          description = "S3 bucket to store edge AMI images"
          type = string
        }
        
        variable "ostree_bucket_name" {
          description = "S3 Storage bucket for storing OSTree content"
          type        = string
        }

        # Imagebuilder server
        module "ec2" {
          source  = "terraform-aws-modules/ec2-instance/aws"
          version = "2.8.0"

          name                          = var.instance_name
          instance_count                = 1
          
          instance_type                 = var.instance_type
          ami                           = var.ami
          subnet_id                     = tolist(module.vpc.public_subnets)[0]
          key_name                      = var.ssh_key
          vpc_security_group_ids        = [module.public_subnet_sg.security_group_id]
          associate_public_ip_address   = true
          ipv6_addresses = null
          private_ips = ["10.0.3.141"]

          iam_instance_profile = aws_iam_instance_profile.imagebuilder_instance_profile.name

          root_block_device = [
            {
              volume_type = "gp2"
              volume_size = 100,
            },
          ]

          ebs_block_device = [
            {
              device_name = "/dev/sdf"
              volume_type = "gp2"
              volume_size = 50
              encrypted   = false
            }
          ]

          tags = local.tags

          user_data = <<-EOF
            #!/bin/bash
            sudo yum -y update
            sudo dnf -y install rhel-system-roles ansible-core yum-utils

            sudo useradd -m ${var.admin_user}
            sudo usermod -aG wheel ${var.admin_user}
            sudo sed -i -e 's/^# %wheel/%wheel/' -e 's/^%wheel/# %wheel/' /etc/sudoers
            sudo sed -i -e 's/^%wheel/# %wheel/' -e 's/^# %wheel/%wheel/' /etc/sudoers
            sudo -u ${var.admin_user} mkdir -p /home/${var.admin_user}/.ssh
            sudo -u ${var.admin_user} bash -c "echo '${aws_key_pair.sshkeypair.public_key}' > /home/${var.admin_user}/.ssh/authorized_keys"
            sudo -u ${var.admin_user} ssh-keygen -t rsa -f /home/admin/.ssh/id_rsa -N ""
            sudo -u ${var.admin_user} cat .ssh/id_rsa.pub >> .ssh/authorized_keys
            sudo -u ${var.admin_user} chmod 700 /home/${var.admin_user}/.ssh
            sudo -u ${var.admin_user} chmod 600 /home/${var.admin_user}/.ssh/authorized_keys
            sudo usermod --password $(echo ${var.admin_password} | openssl passwd -1 -stdin) ${var.admin_user}
            sudo sed -i 's/PasswordAuthentication no/PasswordAuthentication yes/g' /etc/ssh/sshd_config
            sudo systemctl restart sshd
          EOF 
        }

        # Create an IAM Role for EC2 to access S3
        resource "aws_iam_role" "imagebuilder_access_role" {
          name = "imagebuilder_access_role"

          assume_role_policy = jsonencode({
            Version = "2012-10-17"
            Statement = [
              {
                Action = "sts:AssumeRole"
                Effect = "Allow"
                Principal = {
                  Service = "ec2.amazonaws.com"
                }
              }
            ]
          })
        }

        # imagebuilder host permissions to access AWS resources and services 
        resource "aws_iam_policy" "imagebuilder_access_policy" {
          name        = "imagebuilder_access_policy"
          description = "Policy for EC2 to access S3 buckets"

          policy = jsonencode({
            Version = "2012-10-17"
            Statement = [
              {
                Effect   = "Allow"
                Action   = "s3:*"
                Resource = [
                  "arn:aws:s3:::${var.iso_bucket_name}",
                  "arn:aws:s3:::${var.iso_bucket_name}/*",
                  "arn:aws:s3:::${var.ami_bucket_name}",
                  "arn:aws:s3:::${var.ami_bucket_name}/*",
                  "arn:aws:s3:::${var.ostree_bucket_name}",
                  "arn:aws:s3:::${var.ostree_bucket_name}/*"
                ]
              },
              {
                Effect  = "Allow",
                Action  = [
                  "ecr:GetAuthorizationToken",
                  "ecr:BatchCheckLayerAvailability",
                  "ecr:InitiateLayerUpload",
                  "ecr:UploadLayerPart",
                  "ecr:CompleteLayerUpload",
                  "ecr:PutImage",
                  "ecr:CreateRepository",
                  "ecr:DescribeRepositories",
                  "ecr:PutLifeCyclePolicy",
                  "ecr:TagResource",
                  "ecr:ListTagsForResource",
                  "ecr:ListImages"
                ],
                Resource: "*"
              }
            ]
          })
        }

        # Attach the IAM policy to the IAM Role
        resource "aws_iam_role_policy_attachment" "imagebuilder_access_policy_attachment" {
          role       = aws_iam_role.imagebuilder_access_role.name
          policy_arn = aws_iam_policy.imagebuilder_access_policy.arn
        }

        # Create an IAM instance profile for the EC2 instance
        resource "aws_iam_instance_profile" "imagebuilder_instance_profile" {
          name = "imagebuilder_instance_profile"
          role = aws_iam_role.imagebuilder_access_role.name
        }

        # output variables
        output "imagebuilder_ip" {
          description = "Public IP address of the EC2 instance"
          value = module.ec2.public_ip[0]
        }

        output "imagebuilder_dns" {
          description = "Public DNS name of the EC2 instance"
          value = module.ec2.public_dns[0]
        }

        # Security Groups
        module "public_subnet_sg" {
          source  = "terraform-aws-modules/security-group/aws"
          version = "~> 5.0"

          name              = "${var.stack}-vpc-public-subnet-sg"
          description       = "Security group to allow HTTP/HTTPS, SSH access"
          vpc_id            = module.vpc.vpc_id

          # Ingress rules 1) allow SSH traffic from local machine 2) HTTP/HTTPS Traffic from any IP
          ingress_with_cidr_blocks = [
            {
              from_port = 22
              to_port   = 22
              protocol  = "tcp"
              description = "SSH Traffic from this machine"
              cidr_blocks = var.my_ip
            },
            {
              from_port = 80
              to_port   = 80
              protocol  = "tcp"
              description = "HTTP Traffic from any source"
              cidr_blocks = "0.0.0.0/0"
            },
            {
              from_port = 9090
              to_port   = 9090
              protocol  = "tcp"
              description = "Cockpit Traffic from any source"
              cidr_blocks = "0.0.0.0/0"
            },
            {
              from_port = -1
              to_port = -1
              protocol = "icmp"
              cidr_blocks = "0.0.0.0/0"
            },
            {
              from_port = 0
              to_port = 0
              protocol = "-1"
              cidr_blocks = "0.0.0.0/0"
            },
          ]

          #allow all outbound https traffic to internet
          egress_with_cidr_blocks = [
            {
              from_port = 0
              to_port   = 0
              protocol  = "-1"
              description = "All outbound traffic"
              cidr_blocks = "0.0.0.0/0"
            },
          ]
        }

        module "private_subnet_sg" {
          source  = "terraform-aws-modules/security-group/aws"
          version = "~> 5.0"

          name              = "${var.stack}-vpc-private-subnet-sg"
          description       = "Security group to allow HTTP/HTTPS, SSH access from only public subnet"
          vpc_id            = module.vpc.vpc_id
          
          # Ingress rules 1) allow SSH traffic from public subnet 2) HTTPS Traffic from public subnet
          ingress_with_source_security_group_id = [
            {
              from_port             = 22
              to_port               = 22
              protocol              = "tcp"
              description           = "SSH Traffic from public subnet"
              source_security_group_id = module.public_subnet_sg.security_group_id
            },
            {
              from_port             = 443
              to_port               = 443
              protocol              = "tcp"
              description           = "HTTPS Traffic from public subnet"
              source_security_group_id = module.public_subnet_sg.security_group_id
            },
            {
              from_port             = 80
              to_port               = 80
              protocol              = "tcp"
              description           = "HTTP Traffic from public subnet"
              source_security_group_id = module.public_subnet_sg.security_group_id
            },
          ]

          #allow all outbound https traffic to internet
          egress_with_cidr_blocks = [
            {
              from_port = 443
              to_port   = 443
              protocol  = "tcp"
              description = "HTTPS Traffic to any IP"
              cidr_blocks = "0.0.0.0/0"
            },
          ]
        }

        # Create an outbound rule on public subnet security group to allow ssh, http and https traffic flowing to private subnet
        resource "aws_security_group_rule" "allow_ssh_from_public_subnet" {
          type                      = "egress"
          security_group_id         = module.public_subnet_sg.security_group_id
          from_port                 = "22"
          to_port                   = "22"
          protocol                  = "tcp"
          cidr_blocks               = module.vpc.private_subnets_cidr_blocks
        }

        resource "aws_security_group_rule" "allow_http_from_public_subnet" {
          type                      = "egress"
          security_group_id         = module.public_subnet_sg.security_group_id
          from_port                 = "80"
          to_port                   = "80"
          protocol                  = "tcp"
          cidr_blocks               = module.vpc.private_subnets_cidr_blocks
        }

        resource "aws_security_group_rule" "allow_https_from_public_subnet" {
          type                      = "egress"
          security_group_id         = module.public_subnet_sg.security_group_id
          from_port                 = "443"
          to_port                   = "443"
          protocol                  = "tcp"
          cidr_blocks               = module.vpc.private_subnets_cidr_blocks
        }

        terraform {
          required_providers {
            aws = {
              source  = "hashicorp/aws"
              version = "5.63.0"
            }
          }
        }

        # VPC
        module "vpc" {
            source  = "terraform-aws-modules/vpc/aws"
            version = "5.8.1"

            name = "${var.stack}-vpc"

            cidr = local.vpc_cidr
            azs  = local.azs

            private_subnets         = [for k, v in local.azs : cidrsubnet(local.vpc_cidr, 8, k)]
            public_subnets          = [for k, v in local.azs : cidrsubnet(local.vpc_cidr, 8, k + 3)]
            
            create_database_subnet_group = false
            manage_default_network_acl    = false
            manage_default_route_table    = false
            manage_default_security_group = false

            enable_nat_gateway      = true
            single_nat_gateway      = true
            enable_dns_hostnames    = true

            # VPC Flow Logs (Cloudwatch log group and IAM role will be created)
            enable_flow_log                      = true
            create_flow_log_cloudwatch_log_group = true
            create_flow_log_cloudwatch_iam_role  = true
            flow_log_max_aggregation_interval    = 60

            tags = local.tags
        }

        # S3 bucket to store edge iso installers
        module "isos" {
          source  = "terraform-aws-modules/s3-bucket/aws"
          version = "4.1.2"

          bucket     = var.iso_bucket_name
          acl        = "public-read"

          # For example only
          force_destroy = true

          control_object_ownership  = true
          object_ownership          = "ObjectWriter"
          block_public_acls         = false
          attach_public_policy      = true
          block_public_policy       = false
          ignore_public_acls        = false
          restrict_public_buckets   = false
          
          versioning = {
            enabled = true
          }
          
          policy = <<EOF
          {
            "Version": "2012-10-27",
            "Statement": [
              {
                "Effect": "Allow",
                "Principal": "*",
                "Action": "s3:GetObject",
                "Resource": [
                  "arn:aws:s3:::${var.iso_bucket_name}",
                  "arn:aws:s3:::${var.iso_bucket_name}/*"
                ]
              }
            ]
          }
          EOF

          tags = local.tags
        }

        # S3 bucket for storing ostree content
        module "ostree" {
          source  = "terraform-aws-modules/s3-bucket/aws"
          version = "4.1.2"

          bucket     = var.ostree_bucket_name
          acl        = "public-read"

          # For example only
          force_destroy = true

          control_object_ownership  = true
          object_ownership          = "ObjectWriter"
          block_public_acls         = false
          attach_public_policy      = true
          block_public_policy       = false
          ignore_public_acls        = false
          restrict_public_buckets   = false
          
          versioning = {
            enabled = true
          }
          
          policy = <<EOF
          {
            "Version": "2012-10-27",
            "Statement": [
              {
                "Effect": "Allow",
                "Principal": "*",
                "Action": "s3:GetObject",
                "Resource": [
                  "arn:aws:s3:::${var.ostree_bucket_name}",
                  "arn:aws:s3:::${var.ostree_bucket_name}/*"
                ]
              }
            ]
          }
          EOF

          tags = local.tags
        }

        # S3 bucket to store edge ami images
        module "amis" {
          source  = "terraform-aws-modules/s3-bucket/aws"
          version = "4.1.2"

          bucket = var.ami_bucket_name
          acl    = "private"

          # For example only
          force_destroy = true

          control_object_ownership  = true
          object_ownership          = "ObjectWriter"

          versioning = {
            enabled = true
          }
          tags = local.tags
        }

  - name: generate tfvars
    ansible.builtin.template:
      src: input.tfvars.j2
      dest: "{{ tfdir.path }}/input.tfvars"

- name: run tf 
  block:
  - name: init
    ansible.builtin.command:
      cmd: terraform init
      chdir: "{{ tfdir.path }}"
    register: tf_init_result
    ignore_errors: yes
  
  - name: debug init result
    ansible.builtin.debug:
      var: tf_init_result.stdout
    
  - name: plan
    ansible.builtin.command:
      cmd: terraform plan -var-file=input.tfvars
      chdir: "{{ tfdir.path }}"
    when: tf_init_result.rc == 0
    register: tf_plan_result
    ignore_errors: yes
  
  - name: debug plan result
    ansible.builtin.debug:
      var: tf_plan_result.stdout
    when: tf_init_result.rc == 0
    
  - name: apply
    ansible.builtin.command:
      cmd: terraform apply -auto-approve -var-file=input.tfvars
      chdir: "{{ tfdir.path }}"
    when: tf_plan_result.rc == 0
    register: tf_apply_result
    ignore_errors: yes
  
  - name: debug apply result
    ansible.builtin.debug:
      var: tf_apply_result.stdout
    when: tf_plan_result.rc == 0

  - name: fail if errors provisioning
    ansible.builtin.fail:
      msg: "Failed to create infrastructure: \n {{ tf_apply_result.stderr }}"
    when: tf_apply_result.rc != 0
  
  - name: fetch public dns from output
    ansible.builtin.command:
      cmd: terraform output -raw imagebuilder_dns
      chdir: "{{ tfdir.path }}"
    register: tf_output_imagebuilder_dns
  
  - name: set fact
    set_fact:
      imagebuilder_dns: "{{ tf_output_imagebuilder_dns.stdout }}"

  - name: update inventory file
    ansible.builtin.copy:
      dest: ./inventory
      content: |
        ---
        all:
          hosts:
            imagebuilder:
              ansible_host: "{{ imagebuilder_dns }}"
              ansible_port: 22
              ansible_user: "{{ admin_user }}"
              
  - name: add imagebuilder host
    ansible.builtin.add_host:
      hostname: "{{ instance_name }}"
      ansible_host: "{{ imagebuilder_dns }}"
      ansible_port: 22
      ansible_user: "ec2-user"

