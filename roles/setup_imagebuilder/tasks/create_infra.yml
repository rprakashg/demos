---
- name: generate tf scripts
  block:
  - name: create temp directory to store terraform scripts
    ansible.builtin.tempfile:
      state: directory
      suffix: terraform
    register: tfdir

  - name: check if directory exists
    ansible.builtin.stat:
      path: "{{ tfdir.path }}"
    register: dir_stat

  - name: debug tfdir path
    ansible.builtin.debug:
      var: tfdir.path

  - name: create tf script
    ansible.builtin.copy:
      dest: "{{ tfdir.path }}/main.tf"
      content: | 
        provider "aws" {
          region = var.region
        }

        data "aws_availability_zones" "available" {}
        data "aws_caller_identity" "current" {}

        resource "aws_key_pair" "sshkeypair" {
          key_name   = var.ssh_key
          public_key = file("~/.ssh/${var.ssh_key}.pub")
        }

        locals {
            azs                     = slice(data.aws_availability_zones.available.names, 0, 1)
            vpc_cidr                = "10.0.0.0/16" 
                        
            tags = {
                stack: var.stack
            }
        }

        variable "region" {
          description = "AWS region"
          type        = string
        }

        variable "stack" {
          description = "Name of Stack"
          type        = string
        }

        variable instance_name {
          description = "EC2 instance name"
          type        = string
        }

        variable "instance_type" {
          description = "EC2 instance type to use"  
          type = string
        }

        variable ssh_key {
          description = "SSH key pair name"
          type        = string
        }

        variable "ami" {
          description = "AMI to use"
          type = string
        }

        variable "admin_user" {
          description = "Default password for ec2-user account"
          type = string
        }

        variable "admin_password" {
          description = "Default password for ec2-user account"
          type = string
        }

        variable "my_ip" {
          description = "ISP public IP"
          type = string
        }

        module "ec2" {
          source  = "terraform-aws-modules/ec2-instance/aws"
          version = "2.8.0"

          name                          = var.instance_name
          instance_count                = 1
          
          instance_type                 = var.instance_type
          ami                           = var.ami
          subnet_id                     = tolist(module.vpc.public_subnets)[0]
          key_name                      = var.ssh_key
          vpc_security_group_ids        = [module.public_subnet_sg.security_group_id]
          associate_public_ip_address   = true
          ipv6_addresses = null
          private_ips = ["10.0.3.141"]

          root_block_device = [
            {
              volume_type = "gp2"
              volume_size = 100,
            },
          ]

          ebs_block_device = [
            {
              device_name = "/dev/sdf"
              volume_type = "gp2"
              volume_size = 50
              encrypted   = false
            }
          ]

          tags = local.tags

          user_data = <<-EOF
            #!/bin/bash
            sudo yum -y update
            sudo dnf -y install rhel-system-roles ansible-core yum-utils
            sudo useradd -m ${var.admin_user}
            sudo usermod -aG wheel ${var.admin_user}
            sudo sed -i -e 's/^# %wheel/%wheel/' -e 's/^%wheel/# %wheel/' /etc/sudoers
            sudo sed -i -e 's/^%wheel/# %wheel/' -e 's/^# %wheel/%wheel/' /etc/sudoers
            sudo -u ${var.admin_user} mkdir -p /home/${var.admin_user}/.ssh
            sudo -u ${var.admin_user} bash -c "echo '${aws_key_pair.sshkeypair.public_key}' > /home/${var.admin_user}/.ssh/authorized_keys"
            sudo -u ${var.admin_user} ssh-keygen -t rsa -f /home/admin/.ssh/id_rsa -N ""
            sudo -u ${var.admin_user} cat .ssh/id_rsa.pub >> .ssh/authorized_keys
            sudo -u ${var.admin_user} chmod 700 /home/${var.admin_user}/.ssh
            sudo -u ${var.admin_user} chmod 600 /home/${var.admin_user}/.ssh/authorized_keys
            sudo usermod --password $(echo ${var.admin_password} | openssl passwd -1 -stdin) ${var.admin_user}
            sudo sed -i 's/PasswordAuthentication no/PasswordAuthentication yes/g' /etc/ssh/sshd_config
            sudo systemctl restart sshd
          EOF 
        }

        output "imagebuilder_ip" {
          description = "Public IP address of the EC2 instance"
          value = module.ec2.public_ip
        }

        output "imagebuilder_dns" {
          description = "Public DNS name of the EC2 instance"
          value = module.ec2.public_dns
        }

        module "public_subnet_sg" {
          source  = "terraform-aws-modules/security-group/aws"
          version = "~> 5.0"

          name              = "${var.stack}-vpc-public-subnet-sg"
          description       = "Security group to allow HTTP/HTTPS, SSH access"
          vpc_id            = module.vpc.vpc_id

          # Ingress rules 1) allow SSH traffic from local machine 2) HTTP/HTTPS Traffic from any IP
          ingress_with_cidr_blocks = [
            {
              from_port = 22
              to_port   = 22
              protocol  = "tcp"
              description = "SSH Traffic from this machine"
              cidr_blocks = var.my_ip
            },
            {
              from_port = 80
              to_port   = 80
              protocol  = "tcp"
              description = "HTTP Traffic from any source"
              cidr_blocks = "0.0.0.0/0"
            },
            {
              from_port = 9090
              to_port   = 9090
              protocol  = "tcp"
              description = "HTTPS Traffic from any source"
              cidr_blocks = "0.0.0.0/0"
            },
          ]

          #allow all outbound https traffic to internet
          egress_with_cidr_blocks = [
            {
              from_port = 443
              to_port   = 443
              protocol  = "tcp"
              description = "HTTPS Traffic to any IP"
              cidr_blocks = "0.0.0.0/0"
            },
          ]
        }

        module "private_subnet_sg" {
          source  = "terraform-aws-modules/security-group/aws"
          version = "~> 5.0"

          name              = "${var.stack}-vpc-private-subnet-sg"
          description       = "Security group to allow HTTP/HTTPS, SSH access from only public subnet"
          vpc_id            = module.vpc.vpc_id
          
          # Ingress rules 1) allow SSH traffic from public subnet 2) HTTPS Traffic from public subnet
          ingress_with_source_security_group_id = [
            {
              from_port             = 22
              to_port               = 22
              protocol              = "tcp"
              description           = "SSH Traffic from public subnet"
              source_security_group_id = module.public_subnet_sg.security_group_id
            },
            {
              from_port             = 443
              to_port               = 443
              protocol              = "tcp"
              description           = "HTTPS Traffic from public subnet"
              source_security_group_id = module.public_subnet_sg.security_group_id
            },
            {
              from_port             = 80
              to_port               = 80
              protocol              = "tcp"
              description           = "HTTP Traffic from public subnet"
              source_security_group_id = module.public_subnet_sg.security_group_id
            },
          ]

          #allow all outbound https traffic to internet
          egress_with_cidr_blocks = [
            {
              from_port = 443
              to_port   = 443
              protocol  = "tcp"
              description = "HTTPS Traffic to any IP"
              cidr_blocks = "0.0.0.0/0"
            },
          ]
        }

        # Create an outbound rule on public subnet security group to allow ssh, http and https traffic flowing to private subnet
        resource "aws_security_group_rule" "allow_ssh_from_public_subnet" {
          type                      = "egress"
          security_group_id         = module.public_subnet_sg.security_group_id
          from_port                 = "22"
          to_port                   = "22"
          protocol                  = "tcp"
          cidr_blocks               = module.vpc.private_subnets_cidr_blocks
        }

        resource "aws_security_group_rule" "allow_http_from_public_subnet" {
          type                      = "egress"
          security_group_id         = module.public_subnet_sg.security_group_id
          from_port                 = "80"
          to_port                   = "80"
          protocol                  = "tcp"
          cidr_blocks               = module.vpc.private_subnets_cidr_blocks
        }

        resource "aws_security_group_rule" "allow_https_from_public_subnet" {
          type                      = "egress"
          security_group_id         = module.public_subnet_sg.security_group_id
          from_port                 = "443"
          to_port                   = "443"
          protocol                  = "tcp"
          cidr_blocks               = module.vpc.private_subnets_cidr_blocks
        }

        terraform {
          required_providers {
            aws = {
              source  = "hashicorp/aws"
              version = "5.63.0"
            }
          }
        }

        module "vpc" {
            source  = "terraform-aws-modules/vpc/aws"
            version = "5.8.1"

            name = "${var.stack}-vpc"

            cidr = local.vpc_cidr
            azs  = local.azs

            private_subnets         = [for k, v in local.azs : cidrsubnet(local.vpc_cidr, 8, k)]
            public_subnets          = [for k, v in local.azs : cidrsubnet(local.vpc_cidr, 8, k + 3)]
            
            create_database_subnet_group = false
            manage_default_network_acl    = false
            manage_default_route_table    = false
            manage_default_security_group = false

            enable_nat_gateway      = true
            single_nat_gateway      = true
            enable_dns_hostnames    = true

            # VPC Flow Logs (Cloudwatch log group and IAM role will be created)
            enable_flow_log                      = true
            create_flow_log_cloudwatch_log_group = true
            create_flow_log_cloudwatch_iam_role  = true
            flow_log_max_aggregation_interval    = 60

            tags = local.tags
        }

  - name: generate tfvars
    ansible.builtin.template:
      src: input.tfvars.j2
      dest: "{{ tfdir.path }}/input.tfvars"
    when: dir_stat.stat.exists

- name: run tf 
  block:
  - name: init
    ansible.builtin.command:
      cmd: terraform init
      chdir: "{{ tfdir.path }}"
    when: dir_stat.stat.exists  
    register: tf_init_result
    ignore_errors: yes
  
  - name: debug init result
    ansible.builtin.debug:
      var: tf_init_result.stdout
  
  - name: plan
    ansible.builtin.command:
      cmd: terraform plan -var-file=input.tfvars
      chdir: "{{ tfdir.path }}"
    when: tf_init_result.rc == 0
    register: tf_plan_result
    ignore_errors: yes
  
  - name: debug plan result
    ansible.builtin.debug:
      var: tf_plan_result.stdout
  
  - name: apply
    ansible.builtin.command:
      cmd: terraform apply -auto-approve -var-file=input.tfvars
      chdir: "{{ tfdir.path }}"
    when: tf_plan_result.rc == 0
    register: tf_apply_result
    ignore_errors: yes
  
  - name: debug apply result
    ansible.builtin.debug:
      var: tf_apply_result.stdout

  - name: fail if errors provisioning
    ansible.builtin.fail:
      msg: "Failed to create infrastructure: \n {{ tf_apply_result.stderr }}"
    when: tf_apply_result.rc != 0
  
  - name: fetch public dns from output
    ansible.builtin.command:
      cmd: terraform output -raw imagebuilder_dns
      chdir: "{{ tfdir.path }}"
    register: tf_output_imagebuilder_dns
  
  - name: set fact
    set_fact:
      imagebuilder_dns: "{{ tf_output_imagebuilder_dns.stdout }}"

  - name: update inventory file
    ansible.builtin.copy:
      dest: ./inventory
      content: |
        ---
        all:
          hosts:
            imagebuilder:
              ansible_host: "{{ imagebuilder_dns }}"
              ansible_port: 22
              ansible_user: "{{ admin_user }}"